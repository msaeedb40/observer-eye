[
  {
    "projectId": "04ffcf05-bd1b-4963-9267-fbb677d0e974",
    "testId": "8e4bf808-2203-4460-8ffa-f003aaa264b9",
    "userId": "04985488-b071-70f7-1bb6-9d551ae5bf6e",
    "title": "TC001-verify_metric_ingestion_and_retrieval",
    "description": "Test the ingestion of metrics via POST /api/v1/core/metrics/ and retrieval via GET /api/v1/core/metrics/ with query parameters for filtering by name and source.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:8000\"\nMETRICS_ENDPOINT = \"/api/v1/core/metrics/\"\nTIMEOUT = 30\nHEADERS = {\"Content-Type\": \"application/json\"}\n\nINVALID_STRINGS = [' nominal', 'sample', 'placeholder', ' synthetic']\n\ndef assert_no_invalid_strings_in_metrics(metrics):\n    for metric in metrics:\n        for key, value in metric.items():\n            if isinstance(value, str):\n                for invalid_str in INVALID_STRINGS:\n                    assert invalid_str not in value, f\"Found invalid string '{invalid_str}' in metric {key}: {value}\"\n\ndef test_verify_metric_ingestion_and_retrieval():\n    # Step 1: Retrieve metrics initially and confirm it's empty or fresh (no invalid strings)\n    try:\n        resp_get_initial = requests.get(\n            BASE_URL + METRICS_ENDPOINT, timeout=TIMEOUT, headers=HEADERS\n        )\n        assert resp_get_initial.status_code == 200, \\\n            f\"Initial GET metrics failed with status code {resp_get_initial.status_code}\"\n        initial_response = resp_get_initial.json()\n        if isinstance(initial_response, dict) and 'results' in initial_response:\n            initial_metrics = initial_response['results']\n        else:\n            initial_metrics = initial_response\n        assert isinstance(initial_metrics, list), f\"Expected list of metrics, got {type(initial_metrics)}\"\n        # It should be empty or contain no invalid strings if there is fresh data\n        assert_no_invalid_strings_in_metrics(initial_metrics)\n\n        # Step 2: Ingest a new metric via POST\n        metric_to_post = {\n            \"name\": \"cpu_usage_test\",\n            \"source\": \"unit_test_suite\",\n            \"value\": 55.5,\n            \"timestamp\": \"2026-02-06T12:00:00Z\"\n        }\n\n        resp_post = requests.post(\n            BASE_URL + METRICS_ENDPOINT, json=metric_to_post, timeout=TIMEOUT, headers=HEADERS\n        )\n        assert resp_post.status_code in (200, 201), \\\n            f\"POST metric failed with status code {resp_post.status_code}, response: {resp_post.text}\"\n\n        # Step 3: Retrieve metrics filtered by name and source\n        params = {\"name\": metric_to_post[\"name\"], \"source\": metric_to_post[\"source\"]}\n        resp_get_filtered = requests.get(\n            BASE_URL + METRICS_ENDPOINT, params=params, timeout=TIMEOUT, headers=HEADERS\n        )\n        assert resp_get_filtered.status_code == 200, \\\n            f\"Filtered GET metrics failed with status code {resp_get_filtered.status_code}\"\n        filtered_response = resp_get_filtered.json()\n        if isinstance(filtered_response, dict) and 'results' in filtered_response:\n            filtered_metrics = filtered_response['results']\n        else:\n            filtered_metrics = filtered_response\n        assert isinstance(filtered_metrics, list), f\"Expected list, got {type(filtered_metrics)}\"\n        assert len(filtered_metrics) > 0, \"Filtered metrics list is empty after ingestion\"\n\n        # Step 4: Validate that all filtered metrics contain no invalid strings\n        assert_no_invalid_strings_in_metrics(filtered_metrics)\n\n        # Step 5: Validate the posted metric appears in the filtered results\n        matching_metrics = [\n            m for m in filtered_metrics\n            if m.get(\"name\") == metric_to_post[\"name\"] and m.get(\"source\") == metric_to_post[\"source\"]\n        ]\n        assert matching_metrics, \"Ingested metric not found in filtered results\"\n\n    finally:\n        # Clean up: Attempt to delete ingested metric if API supports DELETE (not documented here)\n        # If no DELETE, no cleanup possible through API, so skip.\n        pass\n\ntest_verify_metric_ingestion_and_retrieval()",
    "testStatus": "PASSED",
    "testError": "",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-02-06T23:49:12.189Z",
    "modified": "2026-02-06T23:49:41.412Z"
  },
  {
    "projectId": "04ffcf05-bd1b-4963-9267-fbb677d0e974",
    "testId": "5e95bff6-f10c-4acc-9e74-576ee049ce04",
    "userId": "04985488-b071-70f7-1bb6-9d551ae5bf6e",
    "title": "TC002-verify_log_listing_functionality",
    "description": "Test the retrieval of logs via GET /api/v1/core/logs/ ensuring logs are returned correctly and support any expected filtering or pagination.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:8000\"\nLOGS_ENDPOINT = f\"{BASE_URL}/api/v1/core/logs/\"\nTIMEOUT = 30\n\ndef test_verify_log_listing_functionality():\n    forbidden_substrings = [' nominal', 'sample', 'placeholder', ' synthetic']\n    try:\n        response = requests.get(LOGS_ENDPOINT, timeout=TIMEOUT)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        assert False, f\"GET {LOGS_ENDPOINT} failed with exception: {e}\"\n\n    data = response.json()\n    # Check that data is a list or dict containing logs\n    # logs could be list or could be nested - we assume data is the top-level logs structure\n    # Since no schema is defined for the logs response, we verify none of the fields contain forbidden substrings.\n\n    # Collect all string values recursively from the response json\n    def gather_strings(element):\n        strings = []\n        if isinstance(element, dict):\n            for v in element.values():\n                strings.extend(gather_strings(v))\n        elif isinstance(element, list):\n            for item in element:\n                strings.extend(gather_strings(item))\n        elif isinstance(element, str):\n            strings.append(element)\n        return strings\n\n    all_strings = gather_strings(data)\n    for forbidden in forbidden_substrings:\n        for s in all_strings:\n            assert forbidden not in s, f\"Found forbidden substring '{forbidden}' in log data: '{s}'\"\n\n    # Check that metrics list is initially empty or reflects fresh data since platform was purged\n    # From the PRD, metrics list is presumably separate, but instruction says verify metrics list empty or fresh.\n    # We'll query metrics to verify that:\n\n    metrics_endpoint = f\"{BASE_URL}/api/v1/core/metrics/\"\n    try:\n        metrics_response = requests.get(metrics_endpoint, timeout=TIMEOUT)\n        metrics_response.raise_for_status()\n    except requests.RequestException as e:\n        assert False, f\"GET {metrics_endpoint} failed with exception: {e}\"\n\n    metrics_data = metrics_response.json()\n    # According to PRD, fetching metrics returns a list or dict - we consider it returns list of metrics\n    # We verify list is empty or reasonably empty (fresh platform)\n    if isinstance(metrics_data, list):\n        assert len(metrics_data) == 0, f\"Expected metrics list to be empty after purge, found {len(metrics_data)} metrics.\"\n    elif isinstance(metrics_data, dict):\n        # maybe it has a 'results' or 'metrics' key, check presence of metrics\n        possible_keys = ['results', 'metrics', 'data']\n        found_metrics = None\n        for key in possible_keys:\n            if key in metrics_data:\n                found_metrics = metrics_data[key]\n                break\n        if found_metrics is None:\n            # No recognized keys holding metrics, assume empty\n            pass\n        else:\n            if isinstance(found_metrics, list):\n                assert len(found_metrics) == 0, f\"Expected metrics list to be empty after purge, found {len(found_metrics)} metrics.\"\n            else:\n                # If it's not a list, just check truthy vs falsy\n                assert not found_metrics, f\"Expected metrics list to be empty after purge, found non-empty data.\"\n    else:\n        # Unrecognized format, fail\n        assert False, f\"Unexpected metrics data format: {type(metrics_data)}\"\n\ntest_verify_log_listing_functionality()",
    "testStatus": "PASSED",
    "testError": "",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-02-06T23:49:12.193Z",
    "modified": "2026-02-06T23:49:25.503Z"
  },
  {
    "projectId": "04ffcf05-bd1b-4963-9267-fbb677d0e974",
    "testId": "ad36c414-4b3e-4071-972a-77d78d13340c",
    "userId": "04985488-b071-70f7-1bb6-9d551ae5bf6e",
    "title": "TC005-verify_alert_creation_and_listing",
    "description": "Test the creation of alerts via POST /api/v1/notification/alerts/ and retrieval of alerts via GET /api/v1/notification/alerts/ verifying multi-channel dispatch configurations.",
    "code": "import requests\nimport uuid\n\nBASE_URL = \"http://localhost:8000\"\nHEADERS = {\n    \"Content-Type\": \"application/json\"\n}\nTIMEOUT = 30\n\ndef verify_alert_creation_and_listing():\n    alert_create_url = f\"{BASE_URL}/api/v1/notification/alerts/\"\n    alert_list_url = alert_create_url\n\n    # Prepare alert payload with multiple channel dispatch configurations\n    alert_payload = {\n        \"name\": f\"test-alert-{uuid.uuid4()}\",\n        \"description\": \"Test alert for multi-channel dispatch verification\",\n        \"severity\": \"critical\",\n        \"enabled\": True,\n        \"conditions\": {\n            \"threshold\": 90,\n            \"metric\": \"cpu_usage\"\n        },\n        \"dispatch_channels\": [\n            {\"type\": \"email\", \"recipients\": [\"test@example.com\"]},\n            {\"type\": \"slack\", \"channel\": \"#alerts\"},\n            {\"type\": \"webhook\", \"url\": \"http://localhost:9000/webhook\"}\n        ]\n    }\n\n    alert_id = None\n    try:\n        # Create alert via POST\n        create_resp = requests.post(alert_create_url, json=alert_payload, headers=HEADERS, timeout=TIMEOUT)\n        assert create_resp.status_code == 201, f\"Alert creation failed: {create_resp.text}\"\n        created_alert = create_resp.json()\n        alert_id = created_alert.get(\"id\")\n        assert alert_id is not None and isinstance(alert_id, (int, str)), \"Created alert ID missing or invalid\"\n\n        # Verify created alert fields do not contain hardcoded or mock strings\n        forbidden_strings = [' nominal', 'sample', 'placeholder', ' synthetic']\n        def check_forbidden_strings(obj):\n            if isinstance(obj, dict):\n                for v in obj.values():\n                    check_forbidden_strings(v)\n            elif isinstance(obj, list):\n                for item in obj:\n                    check_forbidden_strings(item)\n            elif isinstance(obj, str):\n                for forbidden in forbidden_strings:\n                    assert forbidden not in obj, f\"Forbidden string '{forbidden}' found in alert data\"\n\n        check_forbidden_strings(created_alert)\n\n        # Retrieve alerts via GET\n        list_resp = requests.get(alert_list_url, headers=HEADERS, timeout=TIMEOUT)\n        assert list_resp.status_code == 200, f\"Alert listing failed: {list_resp.text}\"\n        alert_list_resp = list_resp.json()\n\n        # Adjusted to expect a dict response with a 'results' key listing alerts\n        if isinstance(alert_list_resp, dict) and 'results' in alert_list_resp:\n            alert_list = alert_list_resp['results']\n        else:\n            alert_list = alert_list_resp\n\n        assert isinstance(alert_list, list), \"Alert list response expected to be a list\"\n\n        # Verify none of the alerts contain forbidden strings\n        for alert in alert_list:\n            check_forbidden_strings(alert)\n\n        # Verify metrics list is empty or fresh (no stale/hardcoded metrics)\n        # Given platform just purged, metrics can be queried from /api/v1/core/metrics/\n        metrics_resp = requests.get(f\"{BASE_URL}/api/v1/core/metrics/\", headers=HEADERS, timeout=TIMEOUT)\n        assert metrics_resp.status_code == 200, f\"Metrics listing failed: {metrics_resp.text}\"\n        metrics_resp_json = metrics_resp.json()\n\n        # Adjusted to expect a dict response with 'results' key listing metrics\n        if isinstance(metrics_resp_json, dict) and 'results' in metrics_resp_json:\n            metrics = metrics_resp_json['results']\n        else:\n            metrics = metrics_resp_json\n\n        assert isinstance(metrics, list), \"Metrics response expected to be a list\"\n\n        # Check no metrics contain forbidden strings\n        for metric in metrics:\n            check_forbidden_strings(metric)\n\n    finally:\n        if alert_id:\n            # Cleanup: delete the created alert after test\n            delete_url = f\"{alert_create_url}{alert_id}/\"\n            try:\n                del_resp = requests.delete(delete_url, headers=HEADERS, timeout=TIMEOUT)\n                # Accept 204 No Content or 200 OK for delete success\n                assert del_resp.status_code in (200, 204), f\"Alert deletion failed: {del_resp.text}\"\n            except Exception as e:\n                # If deletion fails, log but do not fail test\n                print(f\"Warning: failed to delete alert {alert_id}: {e}\")\n\nverify_alert_creation_and_listing()\n",
    "testStatus": "PASSED",
    "testError": "",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-02-06T23:49:12.198Z",
    "modified": "2026-02-06T23:50:10.030Z"
  }
]
